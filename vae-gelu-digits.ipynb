{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install and Import libs","metadata":{}},{"cell_type":"code","source":"!pip install keras_preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.utils import plot_model\nfrom tensorflow_addons.layers import GELU\n\nimport numpy as np\nimport json\nimport os\nimport pickle\n\nfrom keras.callbacks import Callback, LearningRateScheduler\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.datasets import mnist, cifar100,cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras_preprocessing.image import load_img, save_img, img_to_array\n\nimport pandas as pd\n\nfrom os import walk, getcwd\nimport h5py\n\nimport scipy\nfrom glob import glob\n\nfrom keras.applications import vgg19\nfrom keras import backend as K\nfrom keras.utils import to_categorical\n\nimport pdb\n\nfrom tensorflow.python.framework.ops import disable_eager_execution\ndisable_eager_execution()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Utils lib","metadata":{}},{"cell_type":"code","source":"#### CALLBACKS\nclass CustomCallback(Callback):\n    \n    def __init__(self, run_folder, print_every_n_batches, initial_epoch, vae):\n        self.epoch = initial_epoch\n        self.run_folder = run_folder\n        self.print_every_n_batches = print_every_n_batches\n        self.vae = vae\n\n    def on_batch_end(self, batch, logs={}):  \n        if batch % self.print_every_n_batches == 0:\n            z_new = np.random.normal(size = (1,self.vae.z_dim))\n            reconst = self.vae.decoder.predict(np.array(z_new))[0].squeeze()\n\n            filepath = os.path.join(self.run_folder, 'images', 'img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\n            if len(reconst.shape) == 2:\n                plt.imsave(filepath, reconst, cmap='gray_r')\n            else:\n                plt.imsave(filepath, reconst)\n\n    def on_epoch_begin(self, epoch, logs={}):\n        self.epoch += 1\n\n        \ndef step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n    '''\n    Wrapper function to create a LearningRateScheduler with step decay schedule.\n    '''\n    def schedule(epoch):\n        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n        \n        return new_lr\n\n    return LearningRateScheduler(schedule)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### LOADER\nclass ImageLabelLoader():\n    def __init__(self, image_folder, target_size):\n        self.image_folder = image_folder\n        self.target_size = target_size\n\n    def build(self, att, batch_size, label = None):\n\n        data_gen = ImageDataGenerator(rescale=1./255)\n        if label:\n            data_flow = data_gen.flow_from_dataframe(\n                att\n                , self.image_folder\n                , x_col='image_id'\n                , y_col=label\n                , target_size=self.target_size \n                , class_mode='other'\n                , batch_size=batch_size\n                , shuffle=True\n            )\n        else:\n            data_flow = data_gen.flow_from_dataframe(\n                att\n                , self.image_folder\n                , x_col='image_id'\n                , target_size=self.target_size \n                , class_mode='input'\n                , batch_size=batch_size\n                , shuffle=True\n            )\n\n        return data_flow\n\n\n\nclass DataLoader():\n    def __init__(self, dataset_name, img_res=(256, 256)):\n        self.dataset_name = dataset_name\n        self.img_res = img_res\n\n    def load_data(self, domain, batch_size=1, is_testing=False):\n        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n        path = glob('./data/%s/%s/*' % (self.dataset_name, data_type))\n\n        batch_images = np.random.choice(path, size=batch_size)\n\n        imgs = []\n        for img_path in batch_images:\n            img = self.imread(img_path)\n            if not is_testing:\n                img = scipy.misc.imresize(img, self.img_res)\n\n                if np.random.random() > 0.5:\n                    img = np.fliplr(img)\n            else:\n                img = scipy.misc.imresize(img, self.img_res)\n            imgs.append(img)\n\n        imgs = np.array(imgs)/127.5 - 1.\n\n        return imgs\n\n    def load_batch(self, batch_size=1, is_testing=False):\n        data_type = \"train\" if not is_testing else \"val\"\n        path_A = glob('./data/%s/%sA/*' % (self.dataset_name, data_type))\n        path_B = glob('./data/%s/%sB/*' % (self.dataset_name, data_type))\n\n        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n        total_samples = self.n_batches * batch_size\n\n        # Sample n_batches * batch_size from each path list so that model sees all\n        # samples from both domains\n        path_A = np.random.choice(path_A, total_samples, replace=False)\n        path_B = np.random.choice(path_B, total_samples, replace=False)\n\n        for i in range(self.n_batches-1):\n            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n            imgs_A, imgs_B = [], []\n            for img_A, img_B in zip(batch_A, batch_B):\n                img_A = self.imread(img_A)\n                img_B = self.imread(img_B)\n\n                img_A = scipy.misc.imresize(img_A, self.img_res)\n                img_B = scipy.misc.imresize(img_B, self.img_res)\n\n                if not is_testing and np.random.random() > 0.5:\n                        img_A = np.fliplr(img_A)\n                        img_B = np.fliplr(img_B)\n\n                imgs_A.append(img_A)\n                imgs_B.append(img_B)\n\n            imgs_A = np.array(imgs_A)/127.5 - 1.\n            imgs_B = np.array(imgs_B)/127.5 - 1.\n\n            yield imgs_A, imgs_B\n\n    def load_img(self, path):\n        img = self.imread(path)\n        img = scipy.misc.imresize(img, self.img_res)\n        img = img/127.5 - 1.\n        return img[np.newaxis, :, :, :]\n\n    def imread(self, path):\n        return scipy.misc.imread(path, mode='RGB').astype(np.float)\n\n\ndef load_model(model_class, folder):\n    \n    with open(os.path.join(folder, 'params.pkl'), 'rb') as f:\n        params = pickle.load(f)\n\n    model = model_class(*params)\n\n    model.load_weights(os.path.join(folder, 'weights/weights.h5'))\n\n    return model\n\n\ndef load_mnist():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n    x_train = x_train.astype('float32') / 255.\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = x_test.astype('float32') / 255.\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    return (x_train, y_train), (x_test, y_test)\n\ndef load_mnist_gan():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n    x_train = (x_train.astype('float32') - 127.5) / 127.5\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = (x_test.astype('float32') - 127.5) / 127.5\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    return (x_train, y_train), (x_test, y_test)\n\n\ndef load_fashion_mnist(input_rows, input_cols, path='./data/fashion/fashion-mnist_train.csv'):\n    #read the csv data\n    df = pd.read_csv(path)\n    #extract the image pixels\n    X_train = df.drop(columns = ['label'])\n    X_train = X_train.values\n    X_train = (X_train.astype('float32') - 127.5) / 127.5\n    X_train = X_train.reshape(X_train.shape[0], input_rows, input_cols, 1)\n    #extract the labels\n    y_train = df['label'].values\n    \n    return X_train, y_train\n\ndef load_safari(folder):\n\n    mypath = os.path.join(\"./data\", folder)\n    txt_name_list = []\n    for (dirpath, dirnames, filenames) in walk(mypath):\n        for f in filenames:\n            if f != '.DS_Store':\n                txt_name_list.append(f)\n                break\n\n    slice_train = int(80000/len(txt_name_list))  ###Setting value to be 80000 for the final dataset\n    i = 0\n    seed = np.random.randint(1, 10e6)\n\n    for txt_name in txt_name_list:\n        txt_path = os.path.join(mypath,txt_name)\n        x = np.load(txt_path)\n        x = (x.astype('float32') - 127.5) / 127.5\n        # x = x.astype('float32') / 255.0\n        \n        x = x.reshape(x.shape[0], 28, 28, 1)\n        \n        y = [i] * len(x)  \n        np.random.seed(seed)\n        np.random.shuffle(x)\n        np.random.seed(seed)\n        np.random.shuffle(y)\n        x = x[:slice_train]\n        y = y[:slice_train]\n        if i != 0: \n            xtotal = np.concatenate((x,xtotal), axis=0)\n            ytotal = np.concatenate((y,ytotal), axis=0)\n        else:\n            xtotal = x\n            ytotal = y\n        i += 1\n        \n    return xtotal, ytotal\n\n\ndef load_cifar(label, num):\n    if num == 10:\n        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n    else:\n        (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode = 'fine')\n\n    train_mask = [y[0]==label for y in y_train]\n    test_mask = [y[0]==label for y in y_test]\n\n    x_data = np.concatenate([x_train[train_mask], x_test[test_mask]])\n    y_data = np.concatenate([y_train[train_mask], y_test[test_mask]])\n\n    x_data = (x_data.astype('float32') - 127.5) / 127.5\n \n    return (x_data, y_data)\n\n\ndef load_celeb(data_name, image_size, batch_size):\n    data_folder = os.path.join(\"./data\", data_name)\n\n    data_gen = ImageDataGenerator(preprocessing_function=lambda x: (x.astype('float32') - 127.5) / 127.5)\n\n    x_train = data_gen.flow_from_directory(data_folder\n                                            , target_size = (image_size,image_size)\n                                            , batch_size = batch_size\n                                            , shuffle = True\n                                            , class_mode = 'input'\n                                            , subset = \"training\"\n                                                )\n\n    return x_train\n\n\ndef load_music(data_name, filename, n_bars, n_steps_per_bar):\n    file = os.path.join(\"./data\", data_name, filename)\n\n    with np.load(file, encoding='bytes') as f:\n        data = f['train']\n\n    data_ints = []\n\n    for x in data:\n        counter = 0\n        cont = True\n        while cont:\n            if not np.any(np.isnan(x[counter:(counter+4)])):\n                cont = False\n            else:\n                counter += 4\n\n        if n_bars * n_steps_per_bar < x.shape[0]:\n            data_ints.append(x[counter:(counter + (n_bars * n_steps_per_bar)),:])\n\n\n    data_ints = np.array(data_ints)\n\n    n_songs = data_ints.shape[0]\n    n_tracks = data_ints.shape[2]\n\n    data_ints = data_ints.reshape([n_songs, n_bars, n_steps_per_bar, n_tracks])\n\n    max_note = 83\n\n    where_are_NaNs = np.isnan(data_ints)\n    data_ints[where_are_NaNs] = max_note + 1\n    max_note = max_note + 1\n\n    data_ints = data_ints.astype(int)\n\n    num_classes = max_note + 1\n\n    \n    data_binary = np.eye(num_classes)[data_ints]\n    data_binary[data_binary==0] = -1\n    data_binary = np.delete(data_binary, max_note,-1)\n\n    data_binary = data_binary.transpose([0,1,2, 4,3])\n    \n\n    return data_binary, data_ints, data\n\n\ndef preprocess_image(data_name, file, img_nrows, img_ncols):\n\n    image_path = os.path.join('./data', data_name, file)\n\n    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = vgg19.preprocess_input(img)\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Variatonal Autoencoder","metadata":{}},{"cell_type":"code","source":"class VariationalAutoencoder():\n    def __init__(self\n        , input_dim\n        , encoder_conv_filters\n        , encoder_conv_kernel_size\n        , encoder_conv_strides\n        , decoder_conv_t_filters\n        , decoder_conv_t_kernel_size\n        , decoder_conv_t_strides\n        , z_dim\n        , encoder_gelu\n        , decoder_gelu\n        , aproximate_gelu\n        , use_batch_norm = False\n        , use_dropout= False\n        ):\n\n        self.name = 'variational_autoencoder'\n\n        self.input_dim = input_dim\n        self.encoder_conv_filters = encoder_conv_filters\n        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n        self.encoder_conv_strides = encoder_conv_strides\n        self.decoder_conv_t_filters = decoder_conv_t_filters\n        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n        self.decoder_conv_t_strides = decoder_conv_t_strides\n        self.z_dim = z_dim\n        self.encoder_gelu = encoder_gelu\n        self.decoder_gelu = decoder_gelu\n        self.aproximate_gelu = aproximate_gelu\n\n        self.use_batch_norm = use_batch_norm\n        self.use_dropout = use_dropout\n\n        self.n_layers_encoder = len(encoder_conv_filters)\n        self.n_layers_decoder = len(decoder_conv_t_filters)\n\n        self._build()\n\n    def _build(self):\n        \n        ### THE ENCODER\n        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n\n        x = encoder_input\n\n        for i in range(self.n_layers_encoder):\n            conv_layer = Conv2D(\n                filters = self.encoder_conv_filters[i]\n                , kernel_size = self.encoder_conv_kernel_size[i]\n                , strides = self.encoder_conv_strides[i]\n                , padding = 'same'\n                , name = 'encoder_conv_' + str(i)\n                )\n\n            x = conv_layer(x)\n\n            if self.use_batch_norm:\n                x = BatchNormalization()(x)\n            \n            if self.encoder_gelu:\n                x = GELU(self.aproximate_gelu)(x)\n            else:\n                x = LeakyReLU()(x)\n\n            if self.use_dropout:\n                x = Dropout(rate = 0.25)(x)\n\n        shape_before_flattening = K.int_shape(x)[1:]\n\n        x = Flatten()(x)\n        self.mu = Dense(self.z_dim, name='mu')(x)\n        self.log_var = Dense(self.z_dim, name='log_var')(x)\n\n        self.encoder_mu_log_var = Model(encoder_input, (self.mu, self.log_var))\n\n        def sampling(args):\n            mu, log_var = args\n            epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n            return mu + K.exp(log_var / 2) * epsilon\n\n        encoder_output = Lambda(sampling, name='encoder_output')([self.mu, self.log_var])\n\n        self.encoder = Model(encoder_input, encoder_output)\n        \n        \n\n        ### THE DECODER\n\n        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\n\n        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n        x = Reshape(shape_before_flattening)(x)\n\n        for i in range(self.n_layers_decoder):\n            conv_t_layer = Conv2DTranspose(\n                filters = self.decoder_conv_t_filters[i]\n                , kernel_size = self.decoder_conv_t_kernel_size[i]\n                , strides = self.decoder_conv_t_strides[i]\n                , padding = 'same'\n                , name = 'decoder_conv_t_' + str(i)\n                )\n\n            x = conv_t_layer(x)\n\n            if i < self.n_layers_decoder - 1:\n                if self.use_batch_norm:\n                    x = BatchNormalization()(x)\n                    \n                if self.decoder_gelu:\n                    x = GELU(self.aproximate_gelu)(x)\n                else:\n                    x = LeakyReLU()(x)\n                    \n                if self.use_dropout:\n                    x = Dropout(rate = 0.25)(x)\n            else:\n                x = Activation('sigmoid')(x)\n\n            \n\n        decoder_output = x\n\n        self.decoder = Model(decoder_input, decoder_output)\n\n        ### THE FULL VAE\n        model_input = encoder_input\n        model_output = self.decoder(encoder_output)\n\n        self.model = Model(model_input, model_output)\n\n\n    def compile(self, learning_rate, r_loss_factor):\n        self.learning_rate = learning_rate\n\n        ### COMPILATION\n        def vae_r_loss(y_true, y_pred):\n            r_loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n            return r_loss_factor * r_loss\n\n        def vae_kl_loss(y_true, y_pred):\n            kl_loss =  -0.5 * K.sum(1 + self.log_var - K.square(self.mu) - K.exp(self.log_var), axis = 1)\n            return kl_loss\n\n        def vae_loss(y_true, y_pred):\n            r_loss = vae_r_loss(y_true, y_pred)\n            kl_loss = vae_kl_loss(y_true, y_pred)\n            return  r_loss + kl_loss\n\n        optimizer = Adam(learning_rate=learning_rate)\n        self.model.compile(optimizer=optimizer, loss = vae_loss,  metrics = [vae_r_loss, vae_kl_loss])\n\n\n    def save(self, folder):\n\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n            os.makedirs(os.path.join(folder, 'viz'))\n            os.makedirs(os.path.join(folder, 'weights'))\n            os.makedirs(os.path.join(folder, 'images'))\n\n        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n            pickle.dump([\n                self.input_dim\n                , self.encoder_conv_filters\n                , self.encoder_conv_kernel_size\n                , self.encoder_conv_strides\n                , self.decoder_conv_t_filters\n                , self.decoder_conv_t_kernel_size\n                , self.decoder_conv_t_strides\n                , self.z_dim\n                , self.use_batch_norm\n                , self.use_dropout\n                ], f)\n\n        self.plot_model(folder)\n\n\n    def load_weights(self, filepath):\n        self.model.load_weights(filepath)\n\n    def train(self, x_train, x_test, batch_size, epochs, run_folder, print_every_n_batches = 100, initial_epoch = 0, lr_decay = 1):\n\n        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\n        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n        \n        checkpoint_filepath=os.path.join(run_folder, \"weights/weights-{epoch:03d}-{loss:.2f}.h5\")\n        checkpoint1 = ModelCheckpoint(checkpoint_filepath, save_weights_only = True, verbose=1)\n        checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only = True, verbose=1)\n\n        callbacks_list = [checkpoint1, checkpoint2, custom_callback, lr_sched]\n\n        history = self.model.fit(     \n            x_train\n            , x_train\n            , batch_size = batch_size\n            , shuffle = True\n            , validation_data = (x_test, x_test)\n            , epochs = epochs\n            , initial_epoch = initial_epoch\n            , callbacks = callbacks_list\n        )\n\n        return history\n\n    def train_with_generator(self, data_flow, epochs, steps_per_epoch, run_folder, print_every_n_batches = 100, initial_epoch = 0, lr_decay = 1, ):\n\n        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\n        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n\n        checkpoint_filepath=os.path.join(run_folder, \"weights/weights-{epoch:03d}-{loss:.2f}.h5\")\n        checkpoint1 = ModelCheckpoint(checkpoint_filepath, save_weights_only = True, verbose=1)\n        checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only = True, verbose=1)\n\n        callbacks_list = [checkpoint1, checkpoint2, custom_callback, lr_sched]\n\n        self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n                \n        self.model.fit_generator(\n            data_flow\n            , shuffle = True\n            , epochs = epochs\n            , initial_epoch = initial_epoch\n            , callbacks = callbacks_list\n            , steps_per_epoch=steps_per_epoch \n            )\n\n\n    \n    def plot_model(self, run_folder):\n        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n        plot_model(self.encoder, to_file=os.path.join(run_folder ,'viz/encoder.png'), show_shapes = True, show_layer_names = True)\n        plot_model(self.decoder, to_file=os.path.join(run_folder ,'viz/decoder.png'), show_shapes = True, show_layer_names = True)","metadata":{"_uuid":"c8f27aca-e2f0-4d8e-9423-d62d36312a11","_cell_guid":"3f6db0ec-1e40-41b8-a21d-50738235772d","_kg_hide-input":false,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Train Code","metadata":{}},{"cell_type":"code","source":"# run params\nSECTION = 'vae'\nRUN_ID = '0002'\nDATA_NAME = 'digits'\nRUN_FOLDER = '/kaggle/working/run/{}/'.format(SECTION)\nRUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n\nif not os.path.exists(RUN_FOLDER):\n    os.makedirs(RUN_FOLDER)\n    os.makedirs(os.path.join(RUN_FOLDER, 'viz'))\n    os.makedirs(os.path.join(RUN_FOLDER, 'images'))\n    os.makedirs(os.path.join(RUN_FOLDER, 'weights'))\n\nmode =  'build' #'load' #","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\n(x_train, y_train), (x_test, y_test) = load_mnist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\nLEARNING_RATE = 0.0005\nR_LOSS_FACTOR = 1000\n\nBATCH_SIZE = 32\nEPOCHS = 200\nPRINT_EVERY_N_BATCHES = 100\nINITIAL_EPOCH = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# architecture and training\nfor parameters in [[False, False], [True, False], [False, True], [True, True]]:\n    \n    encoder_gelu = parameters[0]\n    decoder_gelu = parameters[1]\n    \n    vae = VariationalAutoencoder(\n        input_dim = (28,28,1)\n        , encoder_conv_filters = [32,64,64, 64]\n        , encoder_conv_kernel_size = [3,3,3,3]\n        , encoder_conv_strides = [1,2,2,1]\n        , decoder_conv_t_filters = [64,64,32,1]\n        , decoder_conv_t_kernel_size = [3,3,3,3]\n        , decoder_conv_t_strides = [1,2,2,1]\n        , z_dim = 2\n        , encoder_gelu = encoder_gelu\n        , decoder_gelu = decoder_gelu\n        , aproximate_gelu = False\n    )\n\n    if encoder_gelu == False and decoder_gelu == False:\n        variant_model = 'base'\n    elif encoder_gelu == True and decoder_gelu == False:\n        variant_model = 'encoder_gelu'\n    elif encoder_gelu == False and decoder_gelu == True:\n        variant_model = 'decoder_gelu'\n    elif encoder_gelu == True and decoder_gelu == True:\n        variant_model = 'full_gelu'\n    \n    if mode == 'build':\n        vae.save(RUN_FOLDER+'/'+variant_model)\n    else:\n        vae.load_weights(os.path.join(RUN_FOLDER, str('weights/weights-'+variant_model+\".h5\")))\n\n    vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n\n    history = vae.train(     \n        x_train\n        , x_test\n        , batch_size = BATCH_SIZE\n        , epochs = EPOCHS\n        , run_folder = RUN_FOLDER\n        , print_every_n_batches = PRINT_EVERY_N_BATCHES\n        , initial_epoch = INITIAL_EPOCH\n    )\n\n    with open(str('/kaggle/working/trainHistoryDict-'+variant_model), 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Media de 14 segundos por epoca na GPU T4","metadata":{}},{"cell_type":"markdown","source":"### Carregando históricos e gerando gráficos","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/working/trainHistoryDict-base', \"rb\") as file_pi:\n    history_base = pickle.load(file_pi)\n    \nwith open('/kaggle/working/trainHistoryDict-encoder_gelu', \"rb\") as file_pi:\n    history_encoder_gelu = pickle.load(file_pi)\n\nwith open('/kaggle/working/trainHistoryDict-decoder_gelu', \"rb\") as file_pi:\n    history_decoder_gelu = pickle.load(file_pi)\n    \nwith open('/kaggle/working/trainHistoryDict-full_gelu', \"rb\") as file_pi:\n    history_full_gelu = pickle.load(file_pi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for vae_r_loss\nplt.figure(figsize=(6,4))\nplt.plot(np.log(history_base['vae_r_loss'][2:]), color=(0, 0.4470, 0.7410))\nplt.plot(np.log(history_encoder_gelu['vae_r_loss'][2:]), color=(0.9290, 0.6940, 0.1250))\nplt.plot(np.log(history_decoder_gelu['vae_r_loss'][2:]), color=(0.4660, 0.6740, 0.1880))\nplt.plot(np.log(history_full_gelu['vae_r_loss'][2:]), color=(0.8500, 0.3250, 0.0980))\nplt.legend(['LReLU', 'Encoder-GELU', 'Decoder-GELU', 'Full-GELU'], loc='upper right')\nplt.plot(np.log(history_base['val_vae_r_loss'][2:]), color=(0, 0.4470, 0.7410, 0.4))\nplt.plot(np.log(history_encoder_gelu['val_vae_r_loss'][2:]), color=(0.9290, 0.6940, 0.1250, 0.4))\nplt.plot(np.log(history_decoder_gelu['val_vae_r_loss'][2:]), color=(0.4660, 0.6740, 0.1880, 0.4))\nplt.plot(np.log(history_full_gelu['val_vae_r_loss'][2:]), color=(0.8500, 0.3250, 0.0980, 0.4))\nplt.title('Model Reconstruction Loss')\nplt.ylabel('Log Reconstruction Loss')\nplt.xlabel('Epoch')\nplt.show()\n\n# summarize history for vae_kl_loss\nplt.figure(figsize=(6,4))\nplt.plot(np.log(history_base['vae_kl_loss'][2:]), color=(0, 0.4470, 0.7410))\nplt.plot(np.log(history_encoder_gelu['vae_kl_loss'][2:]), color=(0.9290, 0.6940, 0.1250))\nplt.plot(np.log(history_decoder_gelu['vae_kl_loss'][2:]), color=(0.4660, 0.6740, 0.1880))\nplt.plot(np.log(history_full_gelu['vae_kl_loss'][2:]), color=(0.8500, 0.3250, 0.0980))\nplt.legend(['LReLU', 'Encoder-GELU', 'Decoder-GELU', 'Full-GELU'], loc='lower right')\nplt.plot(np.log(history_base['val_vae_kl_loss'][2:]), color=(0, 0.4470, 0.7410, 0.4))\nplt.plot(np.log(history_encoder_gelu['val_vae_kl_loss'][2:]), color=(0.9290, 0.6940, 0.1250, 0.4))\nplt.plot(np.log(history_decoder_gelu['val_vae_kl_loss'][2:]), color=(0.4660, 0.6740, 0.1880, 0.4))\nplt.plot(np.log(history_full_gelu['val_vae_kl_loss'][2:]), color=(0.8500, 0.3250, 0.0980, 0.4))\nplt.title('Model KL Loss')\nplt.ylabel('Log KL Loss')\nplt.xlabel('Epoch')\nplt.show()\n\n# summarize history for vae_loss\nplt.figure(figsize=(6,4))\nplt.plot(np.log(history_base['loss'][2:]), color=(0, 0.4470, 0.7410))\nplt.plot(np.log(history_encoder_gelu['loss'][2:]), color=(0.9290, 0.6940, 0.1250))\nplt.plot(np.log(history_decoder_gelu['loss'][2:]), color=(0.4660, 0.6740, 0.1880))\nplt.plot(np.log(history_full_gelu['loss'][2:]), color=(0.8500, 0.3250, 0.0980))\nplt.legend(['LReLU', 'Encoder-GELU', 'Decoder-GELU', 'Full-GELU'], loc='upper right')\nplt.plot(np.log(history_base['val_loss'][2:]), color=(0, 0.4470, 0.7410, 0.4))\nplt.plot(np.log(history_encoder_gelu['val_loss'][2:]), color=(0.9290, 0.6940, 0.1250, 0.4))\nplt.plot(np.log(history_decoder_gelu['val_loss'][2:]), color=(0.4660, 0.6740, 0.1880, 0.4))\nplt.plot(np.log(history_full_gelu['val_loss'][2:]), color=(0.8500, 0.3250, 0.0980, 0.4))\nplt.title('Model Loss')\nplt.ylabel('Log Loss')\nplt.xlabel('Epoch')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}